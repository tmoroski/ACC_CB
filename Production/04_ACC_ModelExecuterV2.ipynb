{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b447266a-9d0b-4a9c-ab75-3968b3aa5084",
   "metadata": {},
   "source": [
    "# ACC Single Team Model Excuter (Version 2 - Percentile Based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6aa7fd2-dcc2-4248-80d8-37446a2ae0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../Production/01_ACC_Dependencies.ipynb\n",
    "%run ../Production/02_ACC_ScheduleBuilder.ipynb\n",
    "%run ../Production/03_ACC_CurrentSeasonCollector.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "314a5e5a-d81d-4e65-8d81-a6412cddc189",
   "metadata": {},
   "outputs": [],
   "source": [
    "#regCurrent = regularBoxScoreScraper('duke','2025')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58a768fa-4d41-4c89-abef-8d6c5a480f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Visitor/Neutral</th>\n",
       "      <th>Home/Neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Feb 16, 2025</td>\n",
       "      <td>Louisville</td>\n",
       "      <td>Notre Dame</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date Visitor/Neutral Home/Neutral\n",
       "135  Feb 16, 2025      Louisville   Notre Dame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todaytable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e06839a9-67d8-41fa-b172-17a0c2d4f73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputTable = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52a1a931-bf84-4e82-bacf-30e8b6634398",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonVariable = '2025'\n",
    "seasonPrevVariable = '2024'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51bb3e5c-d598-4974-b0b1-5fe0e6d98e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['louisville', 'notre-dame']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updatedTeamList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f868d213-194c-4767-95d0-46fb8fb69cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:25<00:00, 12.52s/it]\n"
     ]
    }
   ],
   "source": [
    "for team in tqdm(updatedTeamList):\n",
    "    #print(team)\n",
    "    regCurrent = regularBoxScoreScraper(team,seasonVariable)\n",
    "    regPrev = regularBoxScoreScraper(team,seasonPrevVariable).tail(10)\n",
    "    completedReg = pd.concat([regCurrent,regPrev]).sort_values(by='Date', ascending=False).head(10)\n",
    "    \n",
    "    advCurrent = advancedBoxScoreScraper(team,seasonVariable)\n",
    "    advPrev = advancedBoxScoreScraper(team,seasonPrevVariable).tail(10)\n",
    "    completedAdv = pd.concat([advCurrent,advPrev]).sort_values(by='Date', ascending=False).head(10)\n",
    "    # Subtracting fields from our regular box score dataframe that we dont need\n",
    "    completedReg = completedReg[[\n",
    "                                    'Date',\n",
    "                                   \n",
    "                                    'Team_Points'\n",
    "\n",
    "                                ]]\n",
    "    # Subtracting fields from our advanced box score dataframe that we dont need\n",
    "    completedAdv = completedAdv[[\n",
    "                                    'Date',\n",
    "                                   \n",
    "                                    'Pace',\n",
    "                                    'Offensive_EFG',\n",
    "                                    'OffensiveRating',\n",
    "                                    'TrueShootingRate'\n",
    "\n",
    "                                ]]\n",
    "\n",
    "    # Team 1 DataFrame Join\n",
    "    Merged_df = pd.merge(completedReg, completedAdv, on=['Date'], how='left')    \n",
    "    predictors = [\n",
    "                    'Pace',\n",
    "                    'Offensive_EFG',\n",
    "                    'OffensiveRating',\n",
    "                    'TrueShootingRate'    \n",
    "                ]\n",
    "    teamName = []\n",
    "    predictionsLowerBound = []\n",
    "    predictionsUpperBound = []\n",
    "    predictionMean = []\n",
    "    Percentile_10th = []\n",
    "    Percentile_20th = []\n",
    "    Percentile_30th = []\n",
    "    Percentile_40th = []\n",
    "    Percentile_50th = []\n",
    "    Percentile_60th = []\n",
    "    Percentile_65th = []\n",
    "    Percentile_70th = []\n",
    "    Percentile_75th = []\n",
    "    Percentile_80th = []\n",
    "    Percentile_90th = []\n",
    "    DateList = []\n",
    "    TeamList = []\n",
    "    TeamPointsList = []\n",
    "    histTS, binsTS = np.histogram(Merged_df['TrueShootingRate'].astype(float), bins=10)\n",
    "    histPace, binsPace = np.histogram(Merged_df['Pace'].astype(float), bins=10)\n",
    "    histEFG, binsEFG = np.histogram(Merged_df['Offensive_EFG'].astype(float), bins=10)\n",
    "    histRATE, binsRATE = np.histogram(Merged_df['OffensiveRating'].astype(float), bins=10)\n",
    "    randomListTrue =[]\n",
    "    randomListPace =[]\n",
    "    randomListEFG =[]\n",
    "    randomListRate =[]\n",
    "    for x in range(histTS[0]):\n",
    "        randomListTrue.append(random.uniform(binsTS[0],binsTS[1]))   \n",
    "    for x in range(histTS[1]):\n",
    "        randomListTrue.append(random.uniform(binsTS[1],binsTS[2]))   \n",
    "    for x in range(histTS[2]):\n",
    "        randomListTrue.append(random.uniform(binsTS[2],binsTS[3]))   \n",
    "    for x in range(histTS[3]):\n",
    "        randomListTrue.append(random.uniform(binsTS[3],binsTS[4]))   \n",
    "    for x in range(histTS[4]):\n",
    "        randomListTrue.append(random.uniform(binsTS[4],binsTS[5]))   \n",
    "    for x in range(histTS[5]):\n",
    "        randomListTrue.append(random.uniform(binsTS[5],binsTS[6]))   \n",
    "    for x in range(histTS[6]):\n",
    "        randomListTrue.append(random.uniform(binsTS[6],binsTS[7]))\n",
    "    for x in range(histTS[7]):\n",
    "        randomListTrue.append(random.uniform(binsTS[7],binsTS[8]))\n",
    "    for x in range(histTS[8]):\n",
    "        randomListTrue.append(random.uniform(binsTS[8],binsTS[9]))   \n",
    "    for x in range(histTS[9]):\n",
    "        randomListTrue.append(random.uniform(binsTS[9],binsTS[10]))\n",
    "\n",
    "    for x in range(histPace[0]):\n",
    "        randomListPace.append(random.uniform(binsPace[0],binsPace[1]))   \n",
    "    for x in range(histPace[1]):\n",
    "        randomListPace.append(random.uniform(binsPace[1],binsPace[2]))   \n",
    "    for x in range(histPace[2]):\n",
    "        randomListPace.append(random.uniform(binsPace[2],binsPace[3]))   \n",
    "    for x in range(histPace[3]):\n",
    "        randomListPace.append(random.uniform(binsPace[3],binsPace[4]))   \n",
    "    for x in range(histPace[4]):\n",
    "        randomListPace.append(random.uniform(binsPace[4],binsPace[5]))   \n",
    "    for x in range(histPace[5]):\n",
    "        randomListPace.append(random.uniform(binsPace[5],binsPace[6]))   \n",
    "    for x in range(histPace[6]):\n",
    "        randomListPace.append(random.uniform(binsPace[6],binsPace[7]))\n",
    "    for x in range(histPace[7]):\n",
    "        randomListPace.append(random.uniform(binsPace[7],binsPace[8]))\n",
    "    for x in range(histPace[8]):\n",
    "        randomListPace.append(random.uniform(binsPace[8],binsPace[9]))   \n",
    "    for x in range(histPace[9]):\n",
    "        randomListPace.append(random.uniform(binsPace[9],binsPace[10]))      \n",
    "\n",
    "    for x in range(histEFG[0]):\n",
    "        randomListEFG.append(random.uniform(binsEFG[0],binsEFG[1]))   \n",
    "    for x in range(histEFG[1]):\n",
    "        randomListEFG.append(random.uniform(binsEFG[1],binsEFG[2]))   \n",
    "    for x in range(histEFG[2]):\n",
    "        randomListEFG.append(random.uniform(binsEFG[2],binsEFG[3]))   \n",
    "    for x in range(histEFG[3]):\n",
    "        randomListEFG.append(random.uniform(binsEFG[3],binsEFG[4]))   \n",
    "    for x in range(histEFG[4]):\n",
    "        randomListEFG.append(random.uniform(binsEFG[4],binsEFG[5]))   \n",
    "    for x in range(histEFG[5]):\n",
    "        randomListEFG.append(random.uniform(binsEFG[5],binsEFG[6]))   \n",
    "    for x in range(histEFG[6]):\n",
    "        randomListEFG.append(random.uniform(binsEFG[6],binsEFG[7]))\n",
    "    for x in range(histEFG[7]):\n",
    "        randomListEFG.append(random.uniform(binsEFG[7],binsEFG[8]))\n",
    "    for x in range(histEFG[8]):\n",
    "        randomListEFG.append(random.uniform(binsEFG[8],binsEFG[9]))   \n",
    "    for x in range(histEFG[9]):\n",
    "        randomListEFG.append(random.uniform(binsEFG[9],binsEFG[10]))\n",
    "\n",
    "    for x in range(histRATE[0]):\n",
    "        randomListRate.append(random.uniform(binsRATE[0],binsRATE[1]))   \n",
    "    for x in range(histRATE[1]):\n",
    "        randomListRate.append(random.uniform(binsRATE[1],binsRATE[2]))   \n",
    "    for x in range(histRATE[2]):\n",
    "        randomListRate.append(random.uniform(binsRATE[2],binsRATE[3]))   \n",
    "    for x in range(histRATE[3]):\n",
    "        randomListRate.append(random.uniform(binsRATE[3],binsRATE[4]))   \n",
    "    for x in range(histRATE[4]):\n",
    "        randomListRate.append(random.uniform(binsRATE[4],binsRATE[5]))   \n",
    "    for x in range(histRATE[5]):\n",
    "        randomListRate.append(random.uniform(binsRATE[5],binsRATE[6]))   \n",
    "    for x in range(histRATE[6]):\n",
    "        randomListRate.append(random.uniform(binsRATE[6],binsRATE[7]))\n",
    "    for x in range(histRATE[7]):\n",
    "        randomListRate.append(random.uniform(binsRATE[7],binsRATE[8]))\n",
    "    for x in range(histRATE[8]):\n",
    "        randomListRate.append(random.uniform(binsRATE[8],binsRATE[9]))   \n",
    "    for x in range(histRATE[9]):\n",
    "        randomListRate.append(random.uniform(binsRATE[9],binsRATE[10]))\n",
    "    unique_combinations = []\n",
    "\n",
    "    for k in range(len(randomListPace)):\n",
    "        for l in range(len(randomListEFG)):\n",
    "            for m in range(len(randomListRate)):\n",
    "                for n in range(len(randomListTrue)):\n",
    "                    unique_combinations.append((randomListPace[k],randomListEFG[l],randomListRate[m],randomListTrue[n]))\n",
    "    #Loading our team level regular box score dataframe\n",
    "    Merged_dfTEST = pd.read_excel('./HistoricalTrainingData/combinedTeamBoxScoreGameLogHistory.xlsx')\n",
    "    Merged_dfTEST= Merged_dfTEST.dropna()\n",
    "    #regularBoxScoreDFTEST = pd.read_excel('./HistoricalTrainingData/teamRegularBoxScoreGamelogs.xlsx')\n",
    "    #Loading our team level advanced box score dataframe\n",
    "    #advancedBoxScoreDFTEST = pd.read_excel('./HistoricalTrainingData/teamAdvancedBoxScoreGamelogs.xlsx')\n",
    "    # Subtracting fields from our regular box score dataframe that we dont need\n",
    "    #regularBoxScoreDFTEST = regularBoxScoreDFTEST[[\n",
    "    #    'Date',\n",
    "    #    'Team',\n",
    "    #    'Team_Points'\n",
    "\n",
    "    #]]\n",
    "    # Subtracting fields from our advanced box score dataframe that we dont need\n",
    "    #advancedBoxScoreDFTEST = advancedBoxScoreDFTEST[[\n",
    "    #    'Date',\n",
    "    #    'Team',\n",
    "    #    'Pace',\n",
    "    #    'Offensive_EFG',\n",
    "    #    'OffensiveRating',\n",
    "    #    'TrueShootingRate'\n",
    "\n",
    "    #]]\n",
    "\n",
    "    # Team 1 DataFrame Join\n",
    "    #Merged_dfTEST = pd.merge(regularBoxScoreDFTEST, advancedBoxScoreDFTEST, on=['Date','Team'], how='left')\n",
    "\n",
    "    TrainingData = Merged_dfTEST[Merged_dfTEST['Season'].astype(int)<2025]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(TrainingData[predictors], TrainingData['Team_Points'])\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train,y_train)                    \n",
    "    predictions = []\n",
    "    for combo in unique_combinations:\n",
    "        test_params = {'Pace':combo[0],\n",
    "                       'Offensive_EFG':combo[1],\n",
    "                       'OffensiveRating':combo[2],\n",
    "                       'TrueShootingRate':combo[3],\n",
    "                           }\n",
    "        #Creating the test dataframe\n",
    "        TestingData = pd.DataFrame(test_params, columns=['Pace'\n",
    "                                                         ,'Offensive_EFG'\n",
    "                                                         ,'OffensiveRating'\n",
    "                                                         ,'TrueShootingRate'\n",
    "                                                        ],index=[0]\n",
    "                                  )\n",
    "        # Creating our predictions\n",
    "        y_pred=lr.predict(TestingData[predictors])\n",
    "        predictions.append(y_pred[0]) \n",
    "    hist, bins = np.histogram(predictions, bins=10)\n",
    "    predictionsLowerBound.append(bins[0])\n",
    "    predictionsUpperBound.append(bins[-1])\n",
    "    mean = round(sum(predictions)/len(predictions))\n",
    "    predictions.sort()\n",
    "    Percentile_10th.append(np.percentile(predictions,10))\n",
    "    Percentile_20th.append(np.percentile(predictions,20))\n",
    "    Percentile_30th.append(np.percentile(predictions,30))\n",
    "    Percentile_40th.append(np.percentile(predictions,40))\n",
    "    Percentile_50th.append(np.percentile(predictions,50))\n",
    "    Percentile_60th.append(np.percentile(predictions,60))\n",
    "    Percentile_65th.append(np.percentile(predictions,65))\n",
    "    Percentile_70th.append(np.percentile(predictions,70))\n",
    "    Percentile_75th.append(np.percentile(predictions,75))\n",
    "    Percentile_80th.append(np.percentile(predictions,80))\n",
    "    Percentile_90th.append(np.percentile(predictions,90))\n",
    "    predictionMean.append(mean)#\n",
    "    teamName.append(team)\n",
    "    ResultsFrame = pd.DataFrame({\n",
    "                                'Team Name': teamName,\n",
    "                                'Mean Prediction':predictionMean,\n",
    "                                '10th Percentile': Percentile_10th,\n",
    "                                '20th Percentile': Percentile_20th,\n",
    "                                '30th Percentile':Percentile_30th,\n",
    "                                '40th Percentile':Percentile_40th,   \n",
    "                                '50th Percentile':Percentile_50th,\n",
    "                                '60th Percentile':Percentile_60th,   \n",
    "                                '65th Percentile':Percentile_65th,\n",
    "                                '70th Percentile':Percentile_70th,\n",
    "                                '75th Percentile':Percentile_75th,\n",
    "                                '80th Percentile':Percentile_80th,\n",
    "                                '90th Percentile':Percentile_90th\n",
    "                                })\n",
    "    #outputTable = outputTable.append(ResultsFrame) - append has been removed and needed to switch to concat\n",
    "    # concatenate to original\n",
    "    outputTable = pd.concat([outputTable, ResultsFrame])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9efc0a9-f026-470c-bf53-d5438d297d49",
   "metadata": {},
   "source": [
    "### End of Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81f37860-b007-481f-9b23-946c3923ef53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team Name</th>\n",
       "      <th>Mean Prediction</th>\n",
       "      <th>10th Percentile</th>\n",
       "      <th>20th Percentile</th>\n",
       "      <th>30th Percentile</th>\n",
       "      <th>40th Percentile</th>\n",
       "      <th>50th Percentile</th>\n",
       "      <th>60th Percentile</th>\n",
       "      <th>65th Percentile</th>\n",
       "      <th>70th Percentile</th>\n",
       "      <th>75th Percentile</th>\n",
       "      <th>80th Percentile</th>\n",
       "      <th>90th Percentile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>louisville</td>\n",
       "      <td>83</td>\n",
       "      <td>72.917259</td>\n",
       "      <td>77.513086</td>\n",
       "      <td>79.174090</td>\n",
       "      <td>81.266557</td>\n",
       "      <td>82.444299</td>\n",
       "      <td>84.176913</td>\n",
       "      <td>84.822102</td>\n",
       "      <td>85.725954</td>\n",
       "      <td>87.358269</td>\n",
       "      <td>89.683763</td>\n",
       "      <td>96.050124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>notre-dame</td>\n",
       "      <td>71</td>\n",
       "      <td>56.018440</td>\n",
       "      <td>59.539301</td>\n",
       "      <td>64.005405</td>\n",
       "      <td>68.007182</td>\n",
       "      <td>72.555971</td>\n",
       "      <td>75.613645</td>\n",
       "      <td>76.164670</td>\n",
       "      <td>78.032868</td>\n",
       "      <td>78.812585</td>\n",
       "      <td>80.630920</td>\n",
       "      <td>84.395408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Team Name  Mean Prediction  10th Percentile  20th Percentile  \\\n",
       "0  louisville               83        72.917259        77.513086   \n",
       "0  notre-dame               71        56.018440        59.539301   \n",
       "\n",
       "   30th Percentile  40th Percentile  50th Percentile  60th Percentile  \\\n",
       "0        79.174090        81.266557        82.444299        84.176913   \n",
       "0        64.005405        68.007182        72.555971        75.613645   \n",
       "\n",
       "   65th Percentile  70th Percentile  75th Percentile  80th Percentile  \\\n",
       "0        84.822102        85.725954        87.358269        89.683763   \n",
       "0        76.164670        78.032868        78.812585        80.630920   \n",
       "\n",
       "   90th Percentile  \n",
       "0        96.050124  \n",
       "0        84.395408  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542251c0-bbd5-4474-9d6f-b80f19ea7495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e623765-b93c-45fb-90cb-dba95315e7ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
